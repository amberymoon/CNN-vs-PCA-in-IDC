{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Accuracy errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories and principal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 373\n",
    "#20,90,373,1544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(base_dir, 'data')\n",
    "output_dir = os.path.join(base_dir, 'outputs')\n",
    "processed_data_dir = os.path.join(base_dir, 'processed_data')\n",
    "file_path = os.path.join(processed_data_dir, 'data_pca_' + str(dim) + '.pth')\n",
    "files = listdir(data_dir)\n",
    "\n",
    "# numero file presenti\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pca = torch.load(file_path)\n",
    "train_data_pca = data_pca['train']\n",
    "test_data_pca = data_pca['test']\n",
    "train_labels = data_pca['tr_lab']\n",
    "test_labels = data_pca['te_lab']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim, dropout_prob):\n",
    "        super(FeedforwardNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Funzione di training\n",
    "def train(model, train_loader_pca, loss_function, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader_pca:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = loss_function(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader_pca):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader_pca:\n",
    "            out = model(x)\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            all_targets.extend(y.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, np.array(all_targets), np.array(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(targets, predictions):\n",
    "    precision = precision_score(targets, predictions, average='binary')\n",
    "    recall = recall_score(targets, predictions, average='binary')\n",
    "    f1 = f1_score(targets, predictions, average='binary')\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 10\n",
    "results = {}\n",
    "\n",
    "train_data_pca = torch.tensor(train_data_pca, dtype=torch.float32)\n",
    "train_targets = torch.tensor(train_labels, dtype=torch.long)\n",
    "\n",
    "test_data_pca = torch.tensor(test_data_pca, dtype=torch.float32)\n",
    "test_targets = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset_pca = torch.utils.data.TensorDataset(train_data_pca, train_targets)\n",
    "test_dataset_pca = torch.utils.data.TensorDataset(test_data_pca, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 373\n",
      "Epoch 1/100, Train Loss: 0.4159, Train Accuracy: 83.47%, Test Accuracy: 85.64%, Precision: 0.84, Recall: 0.60, F1 Score: 0.70\n",
      "Epoch 2/100, Train Loss: 0.3899, Train Accuracy: 84.14%, Test Accuracy: 85.75%, Precision: 0.85, Recall: 0.60, F1 Score: 0.70\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m test_f1_scores_pca \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 31\u001b[0m     train_loss_pca \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_pca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     train_losses_pca\u001b[38;5;241m.\u001b[39mappend(train_loss_pca)\n\u001b[0;32m     34\u001b[0m     train_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, train_loader_pca)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Solo l'accuratezza per il training\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader_pca, loss_function, optimizer)\u001b[0m\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     17\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_loader_pca:\n\u001b[0;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     20\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(x)\n",
      "File \u001b[1;32mc:\\Users\\noemi\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\noemi\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\noemi\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\noemi\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\noemi\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\noemi\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\noemi\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\noemi\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(iteration):\n",
    "    train_loader_pca = torch.utils.data.DataLoader(train_dataset_pca, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader_pca = torch.utils.data.DataLoader(test_dataset_pca, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    input_dim = train_data_pca.shape[1]\n",
    "    print(f\"Input dimension: {input_dim}\")\n",
    "\n",
    "    hidden_dim = 100 \n",
    "    out_dim = 2 \n",
    "    dropout_prob = 0.5 \n",
    "\n",
    "    # Creazione di una nuova istanza del modello\n",
    "    model = FeedforwardNetwork(input_dim, hidden_dim, out_dim, dropout_prob)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0005)\n",
    "\n",
    "    num_epochs = 100\n",
    "\n",
    "    train_losses_pca = []\n",
    "    train_accuracies_pca = []\n",
    "    test_accuracies_pca = []\n",
    "\n",
    "    train_losses_pca = []\n",
    "    train_accuracies_pca = []\n",
    "    test_accuracies_pca = []\n",
    "    test_precisions_pca = []\n",
    "    test_recalls_pca = []\n",
    "    test_f1_scores_pca = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss_pca = train(model, train_loader_pca, loss_function, optimizer)\n",
    "        train_losses_pca.append(train_loss_pca)\n",
    "\n",
    "        train_accuracy = evaluate(model, train_loader_pca)[0]  # Solo l'accuratezza per il training\n",
    "        train_accuracies_pca.append(train_accuracy)\n",
    "\n",
    "        test_accuracy, test_targets, test_predictions = evaluate(model, test_loader_pca)\n",
    "        test_accuracies_pca.append(test_accuracy)\n",
    "\n",
    "        precision, recall, f1 = calculate_metrics(test_targets, test_predictions)\n",
    "        test_precisions_pca.append(precision)\n",
    "        test_recalls_pca.append(recall)\n",
    "        test_f1_scores_pca.append(f1)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss_pca:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}')\n",
    "\n",
    "    print(f\"Final Test Precision: {test_precisions_pca[-1]:.2f}\")\n",
    "    print(f\"Final Test Recall: {test_recalls_pca[-1]:.2f}\")\n",
    "    print(f\"Final Test F1 Score: {test_f1_scores_pca[-1]:.2f}\")\n",
    "    results[i]= (train_losses_pca[-1], train_accuracies_pca[-1], test_accuracies_pca[-1], test_precisions_pca[-1], test_recalls_pca[-1], test_f1_scores_pca[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'results_'+str(dim)+'.txt'\n",
    "file_path = os.path.join(processed_data_dir, title)\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "print(f\"Risultati {title} salvati in {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard deviation and mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path,'r') as f:\n",
    "    loaded_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_list = []\n",
    "train_accuracies_list = []\n",
    "test_accuracies_list = []\n",
    "test_precisions_list = []\n",
    "test_recall_list = []\n",
    "test_f1_score_list = []\n",
    "\n",
    "for wd, (train_losses_pca, train_accuracies_pca, test_accuracies_pca, test_precisions_pca, test_recalls_pca, test_f1_scores_pca) in loaded_results.items():\n",
    "    train_losses_list.append(train_losses_pca)\n",
    "    train_accuracies_list.append(train_accuracies_pca)\n",
    "    test_accuracies_list.append(test_accuracies_pca)\n",
    "    test_precisions_list.append(test_precisions_pca)\n",
    "    test_recall_list.append(test_recalls_pca)\n",
    "    test_f1_score_list.append(test_f1_scores_pca)\n",
    "\n",
    "\n",
    "train_losses_array = np.array(train_losses_list)\n",
    "train_accuracies_array = np.array(train_accuracies_list)\n",
    "test_accuracies_array = np.array(test_accuracies_list)\n",
    "test_precisions_array = np.array(test_precisions_list)\n",
    "test_recall_array = np.array(test_recall_list)\n",
    "test_f1_score_array = np.array(test_f1_score_list)\n",
    "\n",
    "\n",
    "mean_train_losses = np.mean(train_losses_array, axis=0)\n",
    "mean_train_accuracies = np.mean(train_accuracies_array, axis=0)\n",
    "mean_test_accuracies = np.mean(test_accuracies_array, axis=0)\n",
    "mean_test_precisions = np.mean(test_precisions_array, axis=0)\n",
    "mean_test_recall = np.mean(test_recall_array, axis=0)\n",
    "mean_test_f1_score =np.mean(test_f1_score_array, axis=0)\n",
    "\n",
    "std_train_losses = np.std(train_losses_array, axis=0)\n",
    "std_train_accuracies = np.std(train_accuracies_array, axis=0)\n",
    "std_test_accuracies = np.std(test_accuracies_array, axis=0)\n",
    "std_test_precisions = np.std(test_precisions_array, axis=0)\n",
    "std_test_recall = np.std(test_recall_array, axis=0)\n",
    "std_test_f1_score = np.std(test_f1_score_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_values_3 = torch.load('mean_data_pca_3_le.pth')\n",
    "mean_train_losses_3 = mean_std_values_3['m_loss']\n",
    "mean_train_accuracies_3 = mean_std_values_3['m_train']\n",
    "mean_test_accuracies_3 = mean_std_values_3['m_test']\n",
    "mean_test_precisions_3 = mean_std_values_3['mean_prec']\n",
    "mean_test_recall_3 = mean_std_values_3['mean_rec']\n",
    "mean_test_f1_score_3 = mean_std_values_3['mean_f1']\n",
    "std_train_losses_3 = mean_std_values_3['std_loss']\n",
    "std_train_accuracies_3 = mean_std_values_3['std_train']\n",
    "std_test_accuracies_3 = mean_std_values_3['std_test']\n",
    "std_test_precisions_3 = mean_std_values_3['std_prec']\n",
    "std_test_recall_3 = mean_std_values_3['std_rec']\n",
    "std_test_f1_score_3 = mean_std_values_3['std_f1']\n",
    "\n",
    "mean_std_values_20 = torch.load('mean_data_pca_20_le.pth')\n",
    "mean_train_losses_20 = mean_std_values_20['m_loss']\n",
    "mean_train_accuracies_20 = mean_std_values_20['m_train']\n",
    "mean_test_accuracies_20 = mean_std_values_20['m_test']\n",
    "mean_test_precisions_20 = mean_std_values_20['mean_prec']\n",
    "mean_test_recall_20 = mean_std_values_20['mean_rec']\n",
    "mean_test_f1_score_20 = mean_std_values_20['mean_f1']\n",
    "std_train_losses_20 = mean_std_values_20['std_loss']\n",
    "std_train_accuracies_20 = mean_std_values_20['std_train']\n",
    "std_test_accuracies_20 = mean_std_values_20['std_test']\n",
    "std_test_precisions_20 = mean_std_values_20['std_prec']\n",
    "std_test_recall_20 = mean_std_values_20['std_rec']\n",
    "std_test_f1_score_20 = mean_std_values_20['std_f1']\n",
    "\n",
    "mean_std_values_90 = torch.load('mean_data_pca_90_le.pth')\n",
    "mean_train_losses_90 = mean_std_values_90['m_loss']\n",
    "mean_train_accuracies_90 = mean_std_values_90['m_train']\n",
    "mean_test_accuracies_90 = mean_std_values_90['m_test']\n",
    "mean_test_precisions_90 = mean_std_values_90['mean_prec']\n",
    "mean_test_recall_90 = mean_std_values_90['mean_rec']\n",
    "mean_test_f1_score_90 = mean_std_values_90['mean_f1']\n",
    "std_train_losses_90 = mean_std_values_90['std_loss']\n",
    "std_train_accuracies_90 = mean_std_values_90['std_train']\n",
    "std_test_accuracies_90 = mean_std_values_90['std_test']\n",
    "std_test_precisions_90 = mean_std_values_90['std_prec']\n",
    "std_test_recall_90 = mean_std_values_90['std_rec']\n",
    "std_test_f1_score_90 = mean_std_values_90['std_f1']\n",
    "\n",
    "mean_std_values_373 = torch.load('mean_data_pca_373_le.pth')\n",
    "mean_train_losses_373 = mean_std_values_373['m_loss']\n",
    "mean_train_accuracies_373 = mean_std_values_373['m_train']\n",
    "mean_test_accuracies_373 = mean_std_values_373['m_test']\n",
    "mean_test_precisions_373 = mean_std_values_373['mean_prec']\n",
    "mean_test_recall_373 = mean_std_values_373['mean_rec']\n",
    "mean_test_f1_score_373 = mean_std_values_373['mean_f1']\n",
    "std_train_losses_373 = mean_std_values_373['std_loss']\n",
    "std_train_accuracies_373 = mean_std_values_373['std_train']\n",
    "std_test_accuracies_373 = mean_std_values_373['std_test']\n",
    "std_test_precisions_373 = mean_std_values_373['std_prec']\n",
    "std_test_recall_373 = mean_std_values_373['std_rec']\n",
    "std_test_f1_score_373 = mean_std_values_373['std_f1']\n",
    "\n",
    "mean_std_values_1544 = torch.load('mean_data_pca_1544_le.pth')\n",
    "mean_train_losses_1544 = mean_std_values_1544['m_loss']\n",
    "mean_train_accuracies_1544 = mean_std_values_1544['m_train']\n",
    "mean_test_accuracies_1544 = mean_std_values_1544['m_test']\n",
    "mean_test_precisions_1544 = mean_std_values_1544['mean_prec']\n",
    "mean_test_recall_1544 = mean_std_values_1544['mean_rec']\n",
    "mean_test_f1_score_1544 = mean_std_values_1544['mean_f1']\n",
    "std_train_losses_1544 = mean_std_values_1544['std_loss']\n",
    "std_train_accuracies_1544 = mean_std_values_1544['std_train']\n",
    "std_test_accuracies_1544 = mean_std_values_1544['std_test']\n",
    "std_test_precisions_1544 = mean_std_values_1544['std_prec']\n",
    "std_test_recall_1544 = mean_std_values_1544['std_rec']\n",
    "std_test_f1_score_1544 = mean_std_values_1544['std_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_losses=[mean_train_losses_3, mean_train_losses_20, mean_train_losses_90, mean_train_losses_373, mean_train_losses_1544]\n",
    "std_losses=[std_train_losses_3, std_train_losses_20, std_train_losses_90, std_train_losses_373, std_train_losses_1544]\n",
    "mean_t_accuracies=[mean_train_accuracies_3, mean_train_accuracies_20, mean_train_accuracies_90, mean_train_accuracies_373, mean_train_accuracies_1544]\n",
    "std_t_accuracies=[std_train_accuracies_3, std_train_accuracies_20, std_train_accuracies_90, std_train_accuracies_373, std_train_accuracies_1544]\n",
    "mean_accuracies=[mean_test_accuracies_3, mean_test_accuracies_20, mean_test_accuracies_90, mean_test_accuracies_373, mean_test_accuracies_1544]\n",
    "std_accuracies=[std_test_accuracies_3,std_test_accuracies_20, std_test_accuracies_90, std_test_accuracies_373, std_test_accuracies_1544]\n",
    "mean_precision=[mean_test_precisions_3, mean_test_precisions_20, mean_test_precisions_90, mean_test_precisions_373, mean_test_precisions_1544]\n",
    "std_precision=[std_test_precisions_3, std_test_precisions_20, std_test_precisions_90, std_test_precisions_373, std_test_precisions_1544]\n",
    "mean_recall=[mean_test_recall_3, mean_test_recall_20, mean_test_recall_90, mean_test_recall_373, mean_test_recall_1544]\n",
    "std_recall=[std_test_recall_3, std_test_recall_20, std_test_recall_90, std_test_recall_373, std_test_recall_1544]\n",
    "mean_f1=[mean_test_f1_score_3, mean_test_f1_score_20, mean_test_f1_score_90, mean_test_f1_score_373, mean_test_f1_score_1544]\n",
    "std_f1=[std_test_f1_score_3, std_test_f1_score_20, std_test_f1_score_90, std_test_f1_score_373, std_test_f1_score_1544]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(15, 15))\n",
    "title = 'PCA_train_metrics'\n",
    "dim=[3,20,90,373,1544]\n",
    "\n",
    "axs[0, 0].errorbar(dim, mean_losses, yerr=std_losses, fmt='-o', label='Train Losses')\n",
    "axs[0, 0].set_title('Train Losses')\n",
    "axs[0, 0].set_xlabel('Componenti Principali')\n",
    "axs[0, 0].set_ylabel('Train Loss')\n",
    "axs[0, 0].grid(True)\n",
    "axs[0, 0].legend()\n",
    "\n",
    "axs[0, 1].errorbar(dim, mean_t_accuracies, yerr=std_t_accuracies, fmt='-o', label='Train Accuracies')\n",
    "axs[0, 1].set_title('Train Accuracies')\n",
    "axs[0, 1].set_xlabel('Componenti Principali')\n",
    "axs[0, 1].set_ylabel('Train Accuracy (%)')\n",
    "axs[0, 1].grid(True)\n",
    "axs[0, 1].legend()\n",
    "\n",
    "axs[1, 0].errorbar(dim, mean_accuracies, yerr=std_accuracies, fmt='-o', label='Test Accuracies')\n",
    "axs[1, 0].set_title('Test Accuracies')\n",
    "axs[1, 0].set_xlabel('Componenti Principali')\n",
    "axs[1, 0].set_ylabel('Test Accuracy (%)')\n",
    "axs[1, 0].grid(True)\n",
    "axs[1, 0].legend()\n",
    "\n",
    "axs[1, 1].errorbar(dim, mean_precision, yerr=std_precision, fmt='-o', label='Precisions')\n",
    "axs[1, 1].set_title('Precisions')\n",
    "axs[1, 1].set_xlabel('Componenti Principali')\n",
    "axs[1, 1].set_ylabel('Precision')\n",
    "axs[1, 1].grid(True)\n",
    "axs[1, 1].legend()\n",
    "\n",
    "axs[2, 0].errorbar(dim, mean_recall, yerr=std_recall, fmt='-o', label='Recall')\n",
    "axs[2, 0].set_title('Recall')\n",
    "axs[2, 0].set_xlabel('Componenti Principali')\n",
    "axs[2, 0].set_ylabel('Recall')\n",
    "axs[2, 0].grid(True)\n",
    "axs[2, 0].legend()\n",
    "\n",
    "axs[2, 1].errorbar(dim, mean_f1, yerr=std_f1, fmt='-o', label='F1 Score')\n",
    "axs[2, 1].set_title('F1 Score')\n",
    "axs[2, 1].set_xlabel('Componenti Principali')\n",
    "axs[2, 1].set_ylabel('F1 Score')\n",
    "axs[2, 1].grid(True)\n",
    "axs[2, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(output_dir, title+'.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "title = 'PCA_test_metrics'\n",
    "dim=[3,20,90,373,1544]\n",
    "\n",
    "axs[0, 0].errorbar(dim, mean_accuracies, yerr=std_accuracies, fmt='-o', label='Test Accuracies', color= 'cadetblue')\n",
    "axs[0, 0].set_title('Test Accuracies vs. PC')\n",
    "axs[0, 0].set_xlabel('Componenti Principali')\n",
    "axs[0, 0].set_ylabel('Test Accuracy (%)')\n",
    "axs[0, 0].grid(True)\n",
    "\n",
    "axs[0, 1].errorbar(dim, mean_precision, yerr=std_precision, fmt='-o', label='Precisions', color= 'cadetblue')\n",
    "axs[0, 1].set_title('Precisions vs. PC')\n",
    "axs[0, 1].set_xlabel('Componenti Principali')\n",
    "axs[0, 1].set_ylabel('Precision')\n",
    "axs[0, 1].grid(True)\n",
    "\n",
    "axs[1, 0].errorbar(dim, mean_recall, yerr=std_recall, fmt='-o', label='Recall',color= 'cadetblue')\n",
    "axs[1, 0].set_title('Recall vs. PC')\n",
    "axs[1, 0].set_xlabel('Componenti Principali')\n",
    "axs[1, 0].set_ylabel('Recall')\n",
    "axs[1, 0].grid(True)\n",
    "\n",
    "axs[1, 1].errorbar(dim, mean_f1, yerr=std_f1, fmt='-o', label='F1 Score', color= 'cadetblue')\n",
    "axs[1, 1].set_title('F1 Score vs. PC')\n",
    "axs[1, 1].set_xlabel('Componenti Principali')\n",
    "axs[1, 1].set_ylabel('F1 Score')\n",
    "axs[1, 1].grid(True)\n",
    "\n",
    "fig.savefig(os.path.join(output_dir, title+'.png'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
