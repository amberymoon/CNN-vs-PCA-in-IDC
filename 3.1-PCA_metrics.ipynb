{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### directories and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "output_dir = os.path.join(base_dir, 'outputs')\n",
    "processed_data_dir = os.path.join(base_dir, 'processed_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in [data_dir, output_dir, processed_data_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 32,\n",
    "    'hidden_dim': 100,\n",
    "    'out_dim': 2,\n",
    "    'dropout_prob': 0.5,\n",
    "    'learning_rate': 0.01,\n",
    "    'weight_decay': 0.0005,\n",
    "    'num_epochs': 100\n",
    "}\n",
    "dims = [3, 20, 90, 373, 154]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim, dropout_prob):\n",
    "        super(FeedforwardNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class FeedforwardNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim, dropout_prob):\n",
    "        super(FeedforwardNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train(model, train_loader_pca, loss_function, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader_pca:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = loss_function(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader_pca)\n",
    "\n",
    "def evaluate(model, data_loader_pca):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader_pca:\n",
    "            out = model(x)\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            all_targets.extend(y.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, np.array(all_targets), np.array(all_predictions)\n",
    "\n",
    "def calculate_metrics(targets, predictions):\n",
    "    precision = precision_score(targets, predictions, average='binary')\n",
    "    recall = recall_score(targets, predictions, average='binary')\n",
    "    f1 = f1_score(targets, predictions, average='binary')\n",
    "    return precision, recall, f1\n",
    "\n",
    "def run_training(iteration, train_data, train_labels, test_data, test_labels, config):\n",
    "    results = {}\n",
    "    train_dataset_pca = torch.utils.data.TensorDataset(train_data, train_labels)\n",
    "    test_dataset_pca = torch.utils.data.TensorDataset(test_data, test_labels)\n",
    "    for i in range(iteration):\n",
    "        train_loader_pca = torch.utils.data.DataLoader(train_dataset_pca, batch_size=config['batch_size'], shuffle=True, drop_last=True)\n",
    "        test_loader_pca = torch.utils.data.DataLoader(test_dataset_pca, batch_size=config['batch_size'], shuffle=False)\n",
    "        \n",
    "        input_dim = train_data.shape[1]\n",
    "        model = FeedforwardNetwork(input_dim, config['hidden_dim'], config['out_dim'], config['dropout_prob'])\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "\n",
    "        num_epochs = config['num_epochs']\n",
    "\n",
    "        train_losses_pca = []\n",
    "        train_accuracies_pca = []\n",
    "        test_accuracies_pca = []\n",
    "        test_precisions_pca = []\n",
    "        test_recalls_pca = []\n",
    "        test_f1_scores_pca = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss_pca = train(model, train_loader_pca, loss_function, optimizer)\n",
    "            train_losses_pca.append(train_loss_pca)\n",
    "\n",
    "            train_accuracy = evaluate(model, train_loader_pca)[0]\n",
    "            train_accuracies_pca.append(train_accuracy)\n",
    "\n",
    "            test_accuracy, test_targets, test_predictions = evaluate(model, test_loader_pca)\n",
    "            test_accuracies_pca.append(test_accuracy)\n",
    "\n",
    "            precision, recall, f1 = calculate_metrics(test_targets, test_predictions)\n",
    "            test_precisions_pca.append(precision)\n",
    "            test_recalls_pca.append(recall)\n",
    "            test_f1_scores_pca.append(f1)\n",
    "\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss_pca:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}')\n",
    "\n",
    "        results[i] = (train_losses_pca[-1], train_accuracies_pca[-1], test_accuracies_pca[-1], test_precisions_pca[-1], test_recalls_pca[-1], test_f1_scores_pca[-1])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_for_dimension(dim, processed_data_dir):\n",
    "    file_path = os.path.join(processed_data_dir, f'data_pca_{dim}.pth')\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File {file_path} not found\")\n",
    "    \n",
    "    data_pca = torch.load(file_path)\n",
    "    train_data_pca = torch.tensor(data_pca['train'], dtype=torch.float32)\n",
    "    test_data_pca = torch.tensor(data_pca['test'], dtype=torch.float32)\n",
    "    train_labels = torch.tensor(data_pca['tr_lab'], dtype=torch.long)\n",
    "    test_labels = torch.tensor(data_pca['te_lab'], dtype=torch.long)\n",
    "    \n",
    "    return train_data_pca, test_data_pca, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_plot_results(dims, output_dir):\n",
    "    mean_losses, std_losses = []\n",
    "    mean_t_accuracies, std_t_accuracies = []\n",
    "    mean_accuracies, std_accuracies = []\n",
    "    mean_precision, std_precision = []\n",
    "    mean_recall, std_recall = []\n",
    "    mean_f1, std_f1 = []\n",
    "\n",
    "    for dim in dims:\n",
    "        mean_std_values = torch.load(os.path.join(output_dir, f'mean_data_pca_{dim}_le.pth'))\n",
    "        mean_losses.append(mean_std_values['mean_loss'])\n",
    "        std_losses.append(mean_std_values['std_loss'])\n",
    "        mean_t_accuracies.append(mean_std_values['mean_train'])\n",
    "        std_t_accuracies.append(mean_std_values['std_train'])\n",
    "        mean_accuracies.append(mean_std_values['mean_test'])\n",
    "        std_accuracies.append(mean_std_values['std_test'])\n",
    "        mean_precision.append(mean_std_values['mean_prec'])\n",
    "        std_precision.append(mean_std_values['std_prec'])\n",
    "        mean_recall.append(mean_std_values['mean_rec'])\n",
    "        std_recall.append(mean_std_values['std_rec'])\n",
    "        mean_f1.append(mean_std_values['mean_f1'])\n",
    "        std_f1.append(mean_std_values['std_f1'])\n",
    "\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(15, 15))\n",
    "    metrics = [\n",
    "        ('Mean Loss', mean_losses, std_losses),\n",
    "        ('Mean Train Accuracy', mean_t_accuracies, std_t_accuracies),\n",
    "        ('Mean Test Accuracy', mean_accuracies, std_accuracies),\n",
    "        ('Mean Precision', mean_precision, std_precision),\n",
    "        ('Mean Recall', mean_recall, std_recall),\n",
    "        ('Mean F1 Score', mean_f1, std_f1)\n",
    "    ]\n",
    "\n",
    "    for i, (title, mean_vals, std_vals) in enumerate(metrics):\n",
    "        row, col = divmod(i, 2)\n",
    "        axs[row, col].errorbar(dims, mean_vals, yerr=std_vals, fmt='-o', capsize=5)\n",
    "        axs[row, col].set_title(title)\n",
    "        axs[row, col].set_xlabel('Dimensions')\n",
    "        axs[row, col].set_ylabel('Score')\n",
    "        axs[row, col].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'performance_comparison.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        loaded_results = json.load(f)\n",
    "\n",
    "    train_losses_list = []\n",
    "    train_accuracies_list = []\n",
    "    test_accuracies_list = []\n",
    "    test_precisions_list = []\n",
    "    test_recall_list = []\n",
    "    test_f1_score_list = []\n",
    "\n",
    "    for _, (train_loss, train_acc, test_acc, test_prec, test_rec, test_f1) in loaded_results.items():\n",
    "        train_losses_list.append(train_loss)\n",
    "        train_accuracies_list.append(train_acc)\n",
    "        test_accuracies_list.append(test_acc)\n",
    "        test_precisions_list.append(test_prec)\n",
    "        test_recall_list.append(test_rec)\n",
    "        test_f1_score_list.append(test_f1)\n",
    "\n",
    "    mean_std_dict = {\n",
    "        'mean_loss': np.mean(train_losses_list),\n",
    "        'std_loss': np.std(train_losses_list),\n",
    "        'mean_train': np.mean(train_accuracies_list),\n",
    "        'std_train': np.std(train_accuracies_list),\n",
    "        'mean_test': np.mean(test_accuracies_list),\n",
    "        'std_test': np.std(test_accuracies_list),\n",
    "        'mean_prec': np.mean(test_precisions_list),\n",
    "        'std_prec': np.std(test_precisions_list),\n",
    "        'mean_rec': np.mean(test_recall_list),\n",
    "        'std_rec': np.std(test_recall_list),\n",
    "        'mean_f1': np.mean(test_f1_score_list),\n",
    "        'std_f1': np.std(test_f1_score_list)\n",
    "    }\n",
    "\n",
    "    return mean_std_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in dims:\n",
    "    print(f\"Training for dimension {dim}\")\n",
    "    train_data_pca, test_data_pca, train_labels, test_labels = load_data_for_dimension(dim, processed_data_dir)\n",
    "    results = run_training(10, train_data_pca, train_labels, test_data_pca, test_labels, config)\n",
    "    \n",
    "    # Save results\n",
    "    title = f'results_{dim}.txt'\n",
    "    file_path = os.path.join(processed_data_dir, title)\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    print(f\"Results for dimension {dim} saved in {file_path}\")\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    mean_std_values = calculate_mean_std(file_path)\n",
    "    torch.save(mean_std_values, os.path.join(output_dir, f'mean_data_pca_{dim}_le.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [2, 3, 4, 5]\n",
    "load_and_plot_results(dims, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
